D:\Anconda\python.exe D:/NLPPractice/kgbook-2020/kgbook-2020/chapter3_new/3.3.1_TextClassify/Aggregation/lightGBM/lgbt_model.py
D:\Anconda\lib\site-packages\numpy\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:
D:\Anconda\lib\site-packages\numpy\.libs\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll
D:\Anconda\lib\site-packages\numpy\.libs\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll
  stacklevel=1)
{'task': 'train', 'boosting': 'gbdt', 'objective': 'binary', 'tree_learner': 'serial', 'metric': ['auc', 'binary_logloss'], 'training_metric': True, 'train_data': './../../../data/train_data.txt', 'test_data': './../../../data/test_data.txt', 'header': 'true', 'label_column': 'name:target', 'ignore_column': 'name:applicantFirst', 'categorical_feature': '', 'metric_freq': 1, 'max_bin': 255, 'num_trees': 100, 'learning_rate': 0.225, 'num_leaves': 64, 'feature_fraction': 0.8, 'min_data_in_leaf': 100, 'min_sum_hessian_in_leaf': 5, 'num_threads': 12, 'is_sparse': True, 'two_round': False, 'convert_model_language': 'cpp', 'output_model': 'model.md', 'output_result': 'gbm_pre.txt'}
./../../../data/train_data.txt
D:\Anconda\lib\site-packages\lightgbm\engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument
  warnings.warn("Found `{}` in params. Will use it instead of argument".format(alias))
D:\Anconda\lib\site-packages\lightgbm\basic.py:842: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.
Please use categorical_feature argument of the Dataset constructor to pass this parameter.
  .format(key))
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 16460, number of negative: 5538
[LightGBM] [Info] Total Bins 513
[LightGBM] [Info] Number of data: 21998, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.748250 -> initscore=1.089300
[LightGBM] [Info] Start training from score 1.089300
[1]	training's auc: 0.6396	training's binary_logloss: 0.554675	valid_1's auc: 0.609981	valid_1's binary_logloss: 0.517117
[2]	training's auc: 0.66522	training's binary_logloss: 0.545457	valid_1's auc: 0.642536	valid_1's binary_logloss: 0.51026
[3]	training's auc: 0.670931	training's binary_logloss: 0.542001	valid_1's auc: 0.644225	valid_1's binary_logloss: 0.508815
[4]	training's auc: 0.673151	training's binary_logloss: 0.538005	valid_1's auc: 0.644006	valid_1's binary_logloss: 0.506628
[5]	training's auc: 0.679705	training's binary_logloss: 0.533424	valid_1's auc: 0.652927	valid_1's binary_logloss: 0.502927
[6]	training's auc: 0.683008	training's binary_logloss: 0.530186	valid_1's auc: 0.65751	valid_1's binary_logloss: 0.500851
[7]	training's auc: 0.685393	training's binary_logloss: 0.527743	valid_1's auc: 0.658836	valid_1's binary_logloss: 0.499705
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[8]	training's auc: 0.687547	training's binary_logloss: 0.526502	valid_1's auc: 0.661917	valid_1's binary_logloss: 0.499089
[9]	training's auc: 0.690739	training's binary_logloss: 0.524511	valid_1's auc: 0.662809	valid_1's binary_logloss: 0.498135
[10]	training's auc: 0.692891	training's binary_logloss: 0.522897	valid_1's auc: 0.664739	valid_1's binary_logloss: 0.497212
[11]	training's auc: 0.694242	training's binary_logloss: 0.521635	valid_1's auc: 0.664855	valid_1's binary_logloss: 0.496945
[12]	training's auc: 0.695957	training's binary_logloss: 0.5204	valid_1's auc: 0.666628	valid_1's binary_logloss: 0.496176
[13]	training's auc: 0.698064	training's binary_logloss: 0.519094	valid_1's auc: 0.6672	valid_1's binary_logloss: 0.495586
[14]	training's auc: 0.700964	training's binary_logloss: 0.517823	valid_1's auc: 0.66818	valid_1's binary_logloss: 0.495455
[15]	training's auc: 0.703159	training's binary_logloss: 0.516775	valid_1's auc: 0.667461	valid_1's binary_logloss: 0.4956
[16]	training's auc: 0.705213	training's binary_logloss: 0.515654	valid_1's auc: 0.66763	valid_1's binary_logloss: 0.49532
[17]	training's auc: 0.706915	training's binary_logloss: 0.514666	valid_1's auc: 0.667402	valid_1's binary_logloss: 0.495222
[18]	training's auc: 0.708763	training's binary_logloss: 0.513587	valid_1's auc: 0.668957	valid_1's binary_logloss: 0.494461
[19]	training's auc: 0.710148	training's binary_logloss: 0.512876	valid_1's auc: 0.669488	valid_1's binary_logloss: 0.494193
[20]	training's auc: 0.7126	training's binary_logloss: 0.511662	valid_1's auc: 0.670451	valid_1's binary_logloss: 0.49388
[21]	training's auc: 0.714366	training's binary_logloss: 0.510662	valid_1's auc: 0.671027	valid_1's binary_logloss: 0.493692
[22]	training's auc: 0.716137	training's binary_logloss: 0.509775	valid_1's auc: 0.67229	valid_1's binary_logloss: 0.493268
[23]	training's auc: 0.717401	training's binary_logloss: 0.509024	valid_1's auc: 0.671813	valid_1's binary_logloss: 0.493344
[24]	training's auc: 0.719205	training's binary_logloss: 0.508014	valid_1's auc: 0.672388	valid_1's binary_logloss: 0.493095
[25]	training's auc: 0.721033	training's binary_logloss: 0.506991	valid_1's auc: 0.67331	valid_1's binary_logloss: 0.492952
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[26]	training's auc: 0.721728	training's binary_logloss: 0.506638	valid_1's auc: 0.674141	valid_1's binary_logloss: 0.492593
[27]	training's auc: 0.722994	training's binary_logloss: 0.505912	valid_1's auc: 0.675157	valid_1's binary_logloss: 0.49217
[28]	training's auc: 0.724907	training's binary_logloss: 0.504915	valid_1's auc: 0.676169	valid_1's binary_logloss: 0.491928
[29]	training's auc: 0.726534	training's binary_logloss: 0.504084	valid_1's auc: 0.676305	valid_1's binary_logloss: 0.491949
[30]	training's auc: 0.727861	training's binary_logloss: 0.503417	valid_1's auc: 0.67643	valid_1's binary_logloss: 0.491707
[31]	training's auc: 0.729795	training's binary_logloss: 0.502344	valid_1's auc: 0.676801	valid_1's binary_logloss: 0.491546
[32]	training's auc: 0.731034	training's binary_logloss: 0.501629	valid_1's auc: 0.677534	valid_1's binary_logloss: 0.491458
[33]	training's auc: 0.731883	training's binary_logloss: 0.501149	valid_1's auc: 0.677976	valid_1's binary_logloss: 0.491299
[34]	training's auc: 0.733202	training's binary_logloss: 0.500457	valid_1's auc: 0.679014	valid_1's binary_logloss: 0.490814
[35]	training's auc: 0.735387	training's binary_logloss: 0.499433	valid_1's auc: 0.680588	valid_1's binary_logloss: 0.490377
[36]	training's auc: 0.736457	training's binary_logloss: 0.498812	valid_1's auc: 0.681098	valid_1's binary_logloss: 0.490264
[37]	training's auc: 0.737374	training's binary_logloss: 0.498141	valid_1's auc: 0.681636	valid_1's binary_logloss: 0.49006
[38]	training's auc: 0.738479	training's binary_logloss: 0.497546	valid_1's auc: 0.682378	valid_1's binary_logloss: 0.489563
[39]	training's auc: 0.739621	training's binary_logloss: 0.496954	valid_1's auc: 0.683115	valid_1's binary_logloss: 0.4891
[40]	training's auc: 0.740299	training's binary_logloss: 0.496544	valid_1's auc: 0.683328	valid_1's binary_logloss: 0.488975
[41]	training's auc: 0.741632	training's binary_logloss: 0.495828	valid_1's auc: 0.683677	valid_1's binary_logloss: 0.488878
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[42]	training's auc: 0.741932	training's binary_logloss: 0.495603	valid_1's auc: 0.684185	valid_1's binary_logloss: 0.488715
[43]	training's auc: 0.74303	training's binary_logloss: 0.495039	valid_1's auc: 0.684987	valid_1's binary_logloss: 0.488362
[44]	training's auc: 0.743968	training's binary_logloss: 0.494431	valid_1's auc: 0.685577	valid_1's binary_logloss: 0.488033
[45]	training's auc: 0.745136	training's binary_logloss: 0.493839	valid_1's auc: 0.686868	valid_1's binary_logloss: 0.487557
[46]	training's auc: 0.745607	training's binary_logloss: 0.493464	valid_1's auc: 0.686786	valid_1's binary_logloss: 0.487631
[47]	training's auc: 0.746862	training's binary_logloss: 0.492762	valid_1's auc: 0.688189	valid_1's binary_logloss: 0.487185
[48]	training's auc: 0.747584	training's binary_logloss: 0.492226	valid_1's auc: 0.688411	valid_1's binary_logloss: 0.486779
[49]	training's auc: 0.748304	training's binary_logloss: 0.491711	valid_1's auc: 0.688784	valid_1's binary_logloss: 0.486615
[50]	training's auc: 0.748968	training's binary_logloss: 0.491333	valid_1's auc: 0.688879	valid_1's binary_logloss: 0.486463
[51]	training's auc: 0.749806	training's binary_logloss: 0.490809	valid_1's auc: 0.688589	valid_1's binary_logloss: 0.486589
[52]	training's auc: 0.750972	training's binary_logloss: 0.490233	valid_1's auc: 0.689598	valid_1's binary_logloss: 0.486131
[53]	training's auc: 0.751222	training's binary_logloss: 0.490008	valid_1's auc: 0.689717	valid_1's binary_logloss: 0.486126
[54]	training's auc: 0.75219	training's binary_logloss: 0.489411	valid_1's auc: 0.690267	valid_1's binary_logloss: 0.485896
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[55]	training's auc: 0.752373	training's binary_logloss: 0.489227	valid_1's auc: 0.690512	valid_1's binary_logloss: 0.485723
[56]	training's auc: 0.752517	training's binary_logloss: 0.489013	valid_1's auc: 0.690406	valid_1's binary_logloss: 0.485808
[57]	training's auc: 0.753514	training's binary_logloss: 0.488537	valid_1's auc: 0.69025	valid_1's binary_logloss: 0.485802
[58]	training's auc: 0.754285	training's binary_logloss: 0.488118	valid_1's auc: 0.690672	valid_1's binary_logloss: 0.485642
[59]	training's auc: 0.754886	training's binary_logloss: 0.487732	valid_1's auc: 0.691217	valid_1's binary_logloss: 0.485404
[60]	training's auc: 0.75503	training's binary_logloss: 0.487552	valid_1's auc: 0.691282	valid_1's binary_logloss: 0.485286
[61]	training's auc: 0.755774	training's binary_logloss: 0.487069	valid_1's auc: 0.692042	valid_1's binary_logloss: 0.484972
[62]	training's auc: 0.75664	training's binary_logloss: 0.486552	valid_1's auc: 0.691436	valid_1's binary_logloss: 0.485215
[63]	training's auc: 0.757608	training's binary_logloss: 0.485948	valid_1's auc: 0.692164	valid_1's binary_logloss: 0.484746
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[64]	training's auc: 0.757734	training's binary_logloss: 0.485804	valid_1's auc: 0.692535	valid_1's binary_logloss: 0.484677
[65]	training's auc: 0.758148	training's binary_logloss: 0.485457	valid_1's auc: 0.692218	valid_1's binary_logloss: 0.484766
[66]	training's auc: 0.758768	training's binary_logloss: 0.485037	valid_1's auc: 0.692371	valid_1's binary_logloss: 0.484533
[67]	training's auc: 0.7593	training's binary_logloss: 0.484605	valid_1's auc: 0.692077	valid_1's binary_logloss: 0.48467
[68]	training's auc: 0.760038	training's binary_logloss: 0.484272	valid_1's auc: 0.692624	valid_1's binary_logloss: 0.484479
[69]	training's auc: 0.760493	training's binary_logloss: 0.483941	valid_1's auc: 0.692977	valid_1's binary_logloss: 0.484371
[70]	training's auc: 0.761294	training's binary_logloss: 0.483505	valid_1's auc: 0.692822	valid_1's binary_logloss: 0.484322
[71]	training's auc: 0.762192	training's binary_logloss: 0.483039	valid_1's auc: 0.693371	valid_1's binary_logloss: 0.484129
[72]	training's auc: 0.762768	training's binary_logloss: 0.482623	valid_1's auc: 0.69398	valid_1's binary_logloss: 0.48377
[73]	training's auc: 0.763254	training's binary_logloss: 0.482297	valid_1's auc: 0.693721	valid_1's binary_logloss: 0.483765
[74]	training's auc: 0.763595	training's binary_logloss: 0.481953	valid_1's auc: 0.693294	valid_1's binary_logloss: 0.484054
[75]	training's auc: 0.764585	training's binary_logloss: 0.481378	valid_1's auc: 0.693361	valid_1's binary_logloss: 0.483996
[76]	training's auc: 0.765243	training's binary_logloss: 0.480917	valid_1's auc: 0.693779	valid_1's binary_logloss: 0.483637
[77]	training's auc: 0.765935	training's binary_logloss: 0.480485	valid_1's auc: 0.694312	valid_1's binary_logloss: 0.483356
[78]	training's auc: 0.766744	training's binary_logloss: 0.480005	valid_1's auc: 0.69489	valid_1's binary_logloss: 0.483001
[79]	training's auc: 0.767437	training's binary_logloss: 0.479595	valid_1's auc: 0.695075	valid_1's binary_logloss: 0.48293
[80]	training's auc: 0.767842	training's binary_logloss: 0.47931	valid_1's auc: 0.695478	valid_1's binary_logloss: 0.482739
[81]	training's auc: 0.76826	training's binary_logloss: 0.478916	valid_1's auc: 0.69578	valid_1's binary_logloss: 0.482621
[82]	training's auc: 0.769273	training's binary_logloss: 0.478329	valid_1's auc: 0.696114	valid_1's binary_logloss: 0.482448
[83]	training's auc: 0.770219	training's binary_logloss: 0.477852	valid_1's auc: 0.694778	valid_1's binary_logloss: 0.48299
[84]	training's auc: 0.770802	training's binary_logloss: 0.477472	valid_1's auc: 0.695017	valid_1's binary_logloss: 0.482887
[85]	training's auc: 0.771458	training's binary_logloss: 0.477073	valid_1's auc: 0.695075	valid_1's binary_logloss: 0.482961
[86]	training's auc: 0.772199	training's binary_logloss: 0.47659	valid_1's auc: 0.695395	valid_1's binary_logloss: 0.482836
[87]	training's auc: 0.773076	training's binary_logloss: 0.476078	valid_1's auc: 0.69478	valid_1's binary_logloss: 0.482976
[88]	training's auc: 0.773677	training's binary_logloss: 0.475649	valid_1's auc: 0.694668	valid_1's binary_logloss: 0.483016
[89]	training's auc: 0.774139	training's binary_logloss: 0.475275	valid_1's auc: 0.695213	valid_1's binary_logloss: 0.482806
[90]	training's auc: 0.774278	training's binary_logloss: 0.475064	valid_1's auc: 0.695159	valid_1's binary_logloss: 0.482846
[91]	training's auc: 0.775016	training's binary_logloss: 0.474545	valid_1's auc: 0.694941	valid_1's binary_logloss: 0.482862
[92]	training's auc: 0.77539	training's binary_logloss: 0.474214	valid_1's auc: 0.696131	valid_1's binary_logloss: 0.482404
[93]	training's auc: 0.775651	training's binary_logloss: 0.473971	valid_1's auc: 0.695788	valid_1's binary_logloss: 0.482402
[94]	training's auc: 0.776587	training's binary_logloss: 0.473422	valid_1's auc: 0.696099	valid_1's binary_logloss: 0.482293
[95]	training's auc: 0.777263	training's binary_logloss: 0.472953	valid_1's auc: 0.696221	valid_1's binary_logloss: 0.482155
[96]	training's auc: 0.77745	training's binary_logloss: 0.472766	valid_1's auc: 0.696167	valid_1's binary_logloss: 0.482152
[97]	training's auc: 0.778054	training's binary_logloss: 0.47237	valid_1's auc: 0.696554	valid_1's binary_logloss: 0.482041
[98]	training's auc: 0.778894	training's binary_logloss: 0.471901	valid_1's auc: 0.69685	valid_1's binary_logloss: 0.48191
[99]	training's auc: 0.779252	training's binary_logloss: 0.471598	valid_1's auc: 0.696841	valid_1's binary_logloss: 0.481824
[100]	training's auc: 0.779689	training's binary_logloss: 0.471254	valid_1's auc: 0.697156	valid_1's binary_logloss: 0.481692
Save model...
[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

        evluation of lgb is :
        f1_score = 0.8743155149934811
        accuracy = 0.7843400447427293
        recall = 0.9544548818673498
        log_loss = 7.448774792176237
        auc = 0.55716474500891
    
1.496955156326294

Process finished with exit code 0
